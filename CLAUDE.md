# LinkedIn Hand-Raiser System - Claude Code Instructions

## Project Context
**Company:** Coperniq (B2B SaaS)
**Target:** Energy + MEP (Mechanical, Electrical, Plumbing) Contractors
**Goal:** GTME tool for testing LinkedIn posts for engagement and conversion

## Start Day Protocol
When I say "start day":
1. Read CLAUDE.md, TASK.md, PLANNING.md, BACKLOG.md
2. `git status` + `git log --oneline -5`
3. List blockers and next 3 priorities

## Context Scan (30 seconds)
1. `pwd` → Detect project
2. Load PROJECT_CONTEXT.md → Verify against git state
3. Check: recent commits, uncommitted changes, active worktrees
4. Scan: CLAUDE.md, PLANNING.md, TASK.md, BACKLOG.md

## Directory Structure
```
linkedin-hand-raiser-system/
├── tracking/          # Excel tracker + performance data
├── posts/             # Draft posts + published copy
├── videos/            # Loom scripts + video links
├── scripts/           # Automation scripts
├── docs/              # Strategy docs + playbooks
├── CLAUDE.md          # This file - Claude instructions
├── TASK.md            # Active tasks
├── PLANNING.md        # Sprint goals + strategy
└── BACKLOG.md         # Future ideas queue
```

## Key Files
- `tracking/linkedin_engagement_tracker.xlsx` - Main tracker (generated by `scripts/build_tracker.py`)
- `docs/README.md` - Project overview
- `docs/PROJECT_CONTEXT.md` - Coperniq and target audience context

## Development Patterns

### Excel Tracker Updates
- Run `python scripts/build_tracker.py` to regenerate tracker
- Tracker has 3 tabs: Post Performance, Dashboard, Response Tracker
- Formulas auto-calculate engagement rates and conversion metrics

### Post Naming Convention
- Electrical: `EC-001`, `EC-002`...
- HVAC: `HV-001`, `HV-002`...
- Plumbing: `PL-001`, `PL-002`...

### Pain Points Tracked
1. Material Cost Overruns
2. Labor Burden Blindness
3. Admin Time Waste
4. Cash Flow Delays
5. Job Profitability Opacity

### Post Types
- Hand-Raiser (primary)
- Educational
- Case Study
- Poll/Survey
- Testimonial

## End of Day Protocol
Update these files before closing:
1. **TASK.md** - Mark completed tasks, add new discoveries
2. **BACKLOG.md** - Add any new ideas or future work
3. **PLANNING.md** - Update if strategy changed
4. Commit all changes with descriptive message

## Success Metrics
| Metric | Target |
|--------|--------|
| Post Engagement Rate | >5% |
| DM Conversion Rate | >2% |
| Video→Demo Rate | >30% |
| Demo→Close Rate | >25% |

## Virtual Environment
```bash
# Activate before running Python scripts
source venv/bin/activate

# Regenerate tracker
python scripts/build_tracker.py
```

---

## AI Video Generation (Runway + Cartesia)

### API Configuration

Environment variables in `.env`:
```bash
RUNWAY_API_KEY=key_xxx          # From https://dev.runwayml.com/
CARTESIA_API_KEY=sk_car_xxx     # From https://cartesia.ai
```

### Runway (Video)

| Setting | Value |
|---------|-------|
| API Base | `https://api.dev.runwayml.com` |
| Version Header | `X-Runway-Version: 2024-11-06` |
| Auth | `Authorization: Bearer {key}` |

**Models:**
- `veo3.1_fast` - Fast text-to-video (recommended)
- `veo3.1` - Higher quality text-to-video
- `gen4_turbo` - Image-to-video only

**Endpoints:**
- `POST /v1/text_to_video` - Generate from text
- `POST /v1/image_to_video` - Generate from image
- `GET /v1/tasks/{id}` - Poll for completion

**Duration:** 4, 6, or 8 seconds
**Ratios:** `1280:720`, `720:1280`, `1920:1080`

### Cartesia (Voice)

| Setting | Value |
|---------|-------|
| API Base | `https://api.cartesia.ai` |
| Version Header | `Cartesia-Version: 2025-04-16` |
| Auth | `Authorization: Bearer {key}` |

**Models:**
- `sonic-3` - Latest with emotional tagging (recommended)
- `sonic-2` - Legacy, lower latency

**Features:**
- Emotional tagging: `[laughter]` inline
- 42 languages supported
- ~90ms time-to-first-audio

**Default Voice:** `a0e99841-438c-4a64-b679-ae501e7d6091`

### Video Generation Commands

```bash
# Generate A/B test videos (voice + silent)
python scripts/generate_video.py --post EC-001 --style pain-point --both

# Voice only
python scripts/generate_video.py --post EC-001 --style pain-point --voice

# Silent only
python scripts/generate_video.py --post EC-001 --style text-overlay --no-voice

# List styles
python scripts/generate_video.py --list-styles

# List voices
python scripts/generate_video.py --list-voices
```

### Video Styles

| Style | Use Case |
|-------|----------|
| `pain-point` | Emotional visualization of problem |
| `text-overlay` | Kinetic typography with key words |
| `abstract` | Motion graphics, attention hooks |
| `before-after` | Transformation/solution reveal |

### A/B Testing Framework

| Version | Stack | Schedule |
|---------|-------|----------|
| A | Runway video + Cartesia voice | Monday |
| B | Runway video + text overlay | Wednesday |
| C | Text only (control) | Friday |

### Output Locations

- Raw videos: `videos/runway/`
- Final videos: `videos/runway/final/`
- Voice audio: `videos/runway/audio/`
- Prompt templates: `videos/runway/prompts/`

### Full Documentation

See `docs/API_INTEGRATION.md` for complete API reference.
